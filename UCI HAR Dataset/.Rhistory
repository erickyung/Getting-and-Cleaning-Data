biocLite()
biocLite(c("GenomicFeatures", "AnnotationDbi"))
find.package("devtools")
install.packages("devtools")
find_rtools()
library(devtools)
find_rtools()
find.package("KernSmooth")
install.package("KernSmooth")
install.packages("KernSmooth")
library("KernSmooth")
load("C:\\Users\\hdung\\Desktop\\R-Programming\\.RData")
data
q()
x <- c(1,3,5)
y <- c(3,2,10)
c <- cbind(x,y)
c
class(c)
x <- c(17,14,4,5,13,12,10)
load("C:\\Users\\hdung\\Desktop\\R-Programming\\.RData")
data
ozone <- data[["Ozone"]]
ozone
class(ozone)
ozone[is.na(ozone)]
length(ozone[is.na(ozone)])
q()
install.packages("swirl")
library(swirl)
ls()
install.packages("swirl")
rm(list=ls())
swirl()
5 + 7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z * 2 + 100
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1,
| 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my
my_
main()
bye()
q()
library(swirl)
ls()
rm(list=ls())
swirl()
my_div
1:20
pi:10
15:1
?`:`
seq(1, 20)
seq(0, 10, by=0.5)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each =
| 10)
rep(c(0, 1, 2), each = 10)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Eric")
my_name
paste(my_name, collapse = " ")
paste("Hello", "World!", sep = " ")
paste("Hello", "world!", sep = " ")
paste(1:3, c("X", "Y", "C"), sep = "")
paste(c("X", "Y", "C"), 1:3, sep = "")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf - Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(3,5,7]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(data = 1:20, nrow = 4, ncol = 5)
identical(my_matix, my_matrix2)
identical(my_matrix, my_matrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data, cnames)
colnames(my_data) <- cnames
my_data
bye()
q()
x <- matrix(rnorm(200), 20, 10)
x
apply(x, 1, quantile, probs = c(0.25, 0.75))
apply(x, 2, quantile, probs = c(0.25, 0.75))
x <- c(rnorm(10), runif(10), rnorm(10, 1))
x
f <- gl(3, 10)
f
tapplyx, f, mean)
tapply(x, f, mean)
tapply(x, f, mean, simplify = FALSE)
tapply(x, f, range, simplify = FALSE)
tapply(x, f, range)
split(x, f)
q()
set.seed(1)
rpois(5, 2)
q()
install.packages(c("httr"))
q()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "7581b29871269a714fa7")
class(myapp)
gtoken <- config(token = github_token)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages(c("httpuv"))
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
myapp <- oauth_app("github", "7581b29871269a714fa7")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github <- oauth_endpoints("https://api.github.com/users/jtleek/repos")
github <- oauth_endpoints("github")
myapp <- oauth_app("Getting and Cleaning Data", key="7581b29871269a714fa7", secret = "884ff559ea80bdf56c94b7eb0e738faf51abc15f")
github_token <- oauth2.0_token(github, myapp)
github <- oauth_endpoints("github")
myapp <- oauth_app("github", key="aafb404285d13a45c690", secret = "d15a899417031582c647e5fd8c086ecf485303cf")
github_token <- oauth2.0_token(github, myapp)
github <- oauth_endpoints("github")
myapp <- oauth_app(github, key="aafb404285d13a45c690", secret = "d15a899417031582c647e5fd8c086ecf485303cf")
github_token <- oauth2.0_token(github, myapp)
github <- oauth_endpoints("github")
myapp <- oauth_app("github", "aafb404285d13a45c690", "d15a899417031582c647e5fd8c086ecf485303cf")
github_token <- oauth2.0_token(github, myapp)
github <- oauth_endpoints("github")
myapp <- oauth_app(github, "aafb404285d13a45c690", "d15a899417031582c647e5fd8c086ecf485303cf")
github_token <- oauth2.0_token(github, myapp)
github <- oauth_endpoints("https://github.com")
github <- oauth_endpoints("https://github.com/login/oauth/authorize")
github <- oauth_endpoints("github")
myapp <- oauth_app("github", "aafb404285d13a45c690", "d15a899417031582c647e5fd8c086ecf485303cf")
github_token <- oauth2.0_token(github, myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
names(content(req))
class(content(req))
cont <- content(req)
cont
length(cont)
cont[which(cont %in% c("datasharing"))]
item <- cont[which(cont %in% c("datasharing"))]
item
length(item)
match("datasharing", cont)
cont$owner
toJSON(cont, pretty=TRUE)
library(jsonlite)
toJSON(cont, pretty=TRUE)
jsonData <- toJSON(cont, pretty=TRUE)
names(jsonData)
jsonData
jsonData$owner
class(jsonData)
class(jsonData$owner)
names(jsonData$owner)
cont
jsonData <- toJSON(jsonData, pretty=TRUE)
jsonData <- fromJSON(jsonData)
class(jsonData)
req
cont
cont <- content(req)
library(jsonlite)
cont
jsonContent <- toJSON(cont, pretty = TRUE)
jsonContent
jsonData <- fromJSON(jsonContent)
jsonData
names(jsonData)
jsonData$owner.url
jsonData[["owner.url"]]
jsonData$owner
jsonData$owner$url
jsonData$owner$repos_url
jsonData
jsonData$name
jsonData[[5]]
jsonData$name
jsonData[5]
jsonData[[5]]
jsonData[[name]]
jsonData[["name"]]
jsonData["name"]
jsonData$5
jsonData(50
jsonData(50)
jsonData[5]
jsonData[5, ]
class(jsonData[5, ])
names(jsonData[5, ])
jsonData[5, ]["created_at"]
jsonData[which(jsonData$name = "datasharing")]
jsonData[which(jsonData$name == "datasharing")]
jsonData[jsonData$name = "datasharing", ]
jsonData[jsonData$name == "datasharing", ]
names(jsonData[jsonData$name == "datasharing", ])
jsonData[jsonData$name == "datasharing", ][["created_at"]]
install.packages(c("sqldf"))
q()
setwd("C:/GitHub/Getting-and-Cleaning-Data/UCI HAR Dataset")
getwd()
######################
# Load features list #
######################
features_list <- read.table("./features.txt")
features <- as.character(features_list$V2)
# Remove unwanted characters from the colnames
features <- gsub("\\(","",features)
features <- gsub("\\)","",features)
features <- gsub("-","",features)
features <- gsub(",","",features)
features <- gsub("mean","Mean",features)
features <- gsub("std","Std",features)
#################
# Load test set #
#################
# Subjects whose measures were recorded in the train set
subject_train <- read.table("./train/subject_train.txt")
colnames(subject_train) <- c("subject")
# Values recorded in the train set
values_train <- read.table("./train/x_train.txt")
# Activity (1-Walking, 2-Walking upstairs, etc.) for the train set
activity_train <- read.table("./train/y_train.txt")
colnames(activity_train) <- c("activity")
# Creation of the data frame for the training set
train_data <- data.frame(subject_train$subject, activity_train$activity, values_train)
colnames(train_data) <- c("Subject","Activity", features)
#################
# Load test set #
#################
# Subjects whose measures were recorded in the test set
subject_test <- read.table("./test/subject_test.txt")
colnames(subject_test) <- c("subject")
# Values recorded in the test set
values_test <- read.table("./test/x_test.txt")
# Activity (1-Walking, 2-Walking upstairs, etc.) for the test set
activity_test <- read.table("./test/y_test.txt")
colnames(activity_test) <- c("activity")
# Creation of the data frame for the test set
test_data <- data.frame(subject_test$subject, activity_test$activity, values_test)
colnames(test_data) <- c("Subject","Activity", features)
############################################################
#  Merge the training and test sets to create one data set #
############################################################
all_data <- rbind(train_data,test_data)
# Extracts only the measurements on the mean and standard deviation for each measurement.
indexes_mean <- grep("Mean",features)
indexes_std <- grep("Std",features)
indexes <- c(indexes_mean,indexes_std)
indexes <- sort(indexes)
indexes <- indexes + 2
refined_data <- data.frame(all_data$Subject, all_data$Activity, all_data[,indexes])
colnames(refined_data)[1] <- "Subject"
colnames(refined_data)[2] <- "Activity"
# Uses descriptive activity names to name the activities in the data set
for(i in 1:length(refined_data$Activity)){
if(refined_data$Activity[i] == 1)
refined_data$Activity[i] <- "WALKING"
else if(refined_data$Activity[i] == 2)
refined_data$Activity[i] <- "WALKING_UPSTAIRS"
else if(refined_data$Activity[i] == 3)
refined_data$Activity[i] <- "WALKING_DOWNSTAIRS"
else if(refined_data$Activity[i] == 4)
refined_data$Activity[i] <- "SITTING"
else if(refined_data$Activity[i] == 5)
refined_data$Activity[i] <- "STANDING"
else if(refined_data$Activity[i] == 6)
refined_data$Activity[i] <- "LAYING"
}
# Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
aggdata <- aggregate(refined_data, by=list(refined_data$Subject, refined_data$Activity), FUN=mean, na.rm=TRUE)
aggdata <- subset(aggdata, select = -c(Subject,Activity) )
colnames(aggdata)[1] <- "Subject"
colnames(aggdata)[2] <- "Activity"
tidy_data <- aggdata
write.table(tidy_data, "tidy_data.txt", row.names=FALSE)
names(aggdata)
colnames(aggdata)
aggdata <- aggregate(refined_data, by=list(refined_data$Subject, refined_data$Activity), FUN=mean, na.rm=TRUE)
colnames(aggdata)
head(aggdata)
getwd()
#######################################################################
# Merging the training and the test sets to create one data set       #
#######################################################################
# Read training data
train_x <- read.table("train/X_train.txt")
train_y <- read.table("train/y_train.txt")
# Read test data
test_x <- read.table("test/X_test.txt")
test_y <- read.table("test/y_test.txt")
# Read feature names
features <- read.table("features.txt")
# Set column headers for training and test data
names(train_x) <- features[,2]
names(train_y) <- c("activity")
names(test_x) <- features[,2]
names(test_y) <- c("activity")
# Combine data
dataset <- rbind(cbind(train_x, train_y), cbind(test_x, test_y))
#######################################################################
# Extracting only the measurements on the mean and standard deviation #
#######################################################################
# Get list of column for mean and std (with keeping activity)
col_nums <- grep("mean\\(|std\\(|activity", names(dataset))
dataset <- dataset[, col_nums]
#######################################################################
# Using descriptive activity names                                    #
#######################################################################
# Read activity names from file
activity_names <- read.table("activity_labels.txt")
# Set column names
names(activity_names) <- c("activity", "activityName")
# Use factor type to set activity labels in data set
dataset$activity <- factor(dataset$activity, levels=activity_names$activity,
labels= activity_names$activityName)
#######################################################################
# Appropriately labels the data set with descriptive variable names   #
#######################################################################
# Mostly done in the first step to easier accessing columns
# Remove/Replace minuses and braces from column names
names(dataset) <- sub("-", "_", names(dataset))
names(dataset) <- sub("\\(\\)", "", names(dataset))
#######################################################################
# Creating tidy data set with the average of each variable            #
# for each activity and each subject                                  #
#######################################################################
train_sub <- read.table("train/subject_train.txt")
test_sub <- read.table("test/subject_test.txt")
dataset$subject <- rbind(train_sub, test_sub)[, 1]
tidy_dataset <- aggregate(data.matrix(dataset[, 1:65]) ~ activity+subject,
data=dataset, mean)
write.table(tidy_dataset, file="tidy_dataset.txt", row.names=FALSE)
feature[, 2]
features[, 2]
features
install.packages("plyr")
#######################################
# Getting and Cleaning Data - Project
# Author : Antisyzygy
#######################################
# Dependencies
library(plyr)
# Read the data
# assumes setwd("~/UCI HAR Dataset")
features <- read.table('features.txt')
features <- as.character(features$V2)
labels <- read.table('activity_labels.txt')
labels <- as.character(labels$V2)
y_train <- read.table('train/y_train.txt')
x_train <- read.table('train/X_train.txt')
subject_test <- read.table('test/subject_test.txt')
y_test <- read.table('test/y_test.txt')
x_test <- read.table('test/X_test.txt')
subject_train <- read.table('train/subject_train.txt')
# Clean up feature and label names
labels <- tolower(labels)
labels <- gsub("_", " ", labels, ignore.case = TRUE)
features <- tolower(features)
features <- gsub("\\(\\)", "", features, ignore.case = TRUE)
features <- gsub("\\(", " ", features, ignore.case = TRUE)
features <- gsub("\\)", "", features, ignore.case = TRUE)
features <- gsub(",", " ", features, ignore.case = TRUE)
features <- gsub("-", " ", features, ignore.case = TRUE)
features <- gsub("^[t]", "time ", features, ignore.case = TRUE)
features <- gsub("^[f]", "frequency ", features, ignore.case = TRUE)
features <- gsub("angle\\(t", "angle(time ", features, ignore.case = FALSE)
features[556] <- paste(gsub(")", "", features[556], ignore.case = TRUE),")", sep="")
# Assign human-readable categories
y_train <- as.data.frame(factor(y_train$V1, levels=c(1,2,3,4,5,6), labels=labels) )
y_test <- as.data.frame(factor(y_test$V1, levels=c(1,2,3,4,5,6), labels=labels) )
rm(labels)
# Assign variable names
names(y_train) <- 'activity'
names(x_train) <- features
names(subject_train) <- "subject id"
names(y_test) <- 'activity'
names(x_test) <- features
names(subject_test) <- "subject id"
rm(features)
# Keep only Mean/STD columns
x_train <- x_train[,grep("mean|std", names(x_train), ignore.case = TRUE)]
x_test <- x_test[,grep("mean|std", names(x_test), ignore.case = TRUE)]
# Create the training/testing data frames
training_data <- as.data.frame(c(subject_train, y_train, x_train))
testing_data <- as.data.frame(c(subject_test, y_test, x_test))
rm(x_train, y_train, subject_train, x_test, y_test, subject_test)
# Merge training/testing into final data frame
combined <- rbind(training_data, testing_data)
rm(training_data, testing_data)
# Make smaller tidy data set
out <- ddply(combined, .(subject.id, activity), numcolwise(mean))
# Change column names, since these are no longer the same variables
names(out) <- c(names(out[,1:2]), gsub("^", "avg.", names(out[,3:ncol(out)])))
# Save all the output
write.table(combined, "combined.txt", row.names = FALSE)
write.table(out, "output.txt", row.names = FALSE)
library(data.table)
## Setup: create data dir and download dataset
if (!file.exists("data")) {
dir.create("data")
}
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",
"./data/getdata-projectfiles-UCI HAR Dataset.zip")
unzip("./data//getdata-projectfiles-UCI HAR Dataset.zip", exdir = "./data")
# Load the relevant data merging train and test data
X <- data.table(read.table("./data/UCI HAR Dataset/train/X_train.txt"))
X <- rbindlist(list(X, data.table(read.table("./data/UCI HAR Dataset/test/X_test.txt"))))
fnames <- fread("./data//UCI HAR Dataset//features.txt")
setnames(X,fnames[,V2])
subject <- fread("./data/UCI HAR Dataset//train/subject_train.txt")
subject <- rbindlist(list(subject, fread("./data/UCI HAR Dataset//test/subject_test.txt")))
y <- fread("./data/UCI HAR Dataset//train/y_train.txt")
y <- rbindlist(list(y, fread("./data/UCI HAR Dataset//test/y_test.txt")))
# Select only Mean and STD columns
meanAndStdColumns <- grep(".*(mean\\(\\)|std\\(\\)).*", names(X))
X <- X[, meanAndStdColumns, with = FALSE]
# Join the labels and the subjects
X[, labels := y]
X[, subject := subject]
# Prepare the activity labels
activity_labels <- fread("./data/UCI HAR Dataset//activity_labels.txt")
setnames(activity_labels, c("id", "activitydescription"))
# Set the activity labels names
setkey(activity_labels, id)
setkey(X, labels)
X <- X[activity_labels]
C <- X[,labels:=NULL]
# Rename the variable names
nX <- tolower(names(X))
nX <- gsub("-", "", nX)
nX <- gsub("\\(\\)", "", nX)
setnames(X, nX)
# create and write the tidy dataset with the means
tidy <- X[,lapply(.SD, mean), by=list(subject, activitydescription)]
write.table(tidy, "tidy.txt", row.names = FALSE)
